{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea843de",
   "metadata": {},
   "source": [
    "# Homework information\n",
    "\n",
    "\n",
    "**Students:** Черкашина Елизавета Андреевна, Мешков Михаил Алексеевич\n",
    "\n",
    "**Master’s programme:** Data Analytics and Social Statistics\n",
    "\n",
    "**Task:**  Module 2. Hard skills project № 4 `Text analysis'\n",
    "\n",
    "**Date:** 17.12.2024  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fa887",
   "metadata": {},
   "source": [
    "## Information about environment versions\n",
    "\n",
    "- Python 3.12.7\n",
    "- Pandas 2.2.3\n",
    "- Matplotlib 3.9.2\n",
    "- spacy/flair/ stanza/ nltk - *после того как определимся с пакетом*\n",
    "- Scikit-learn  1.5.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2583ebf",
   "metadata": {},
   "source": [
    "# Описание задачи (как сделаем можно убрать)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a53628",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "**To receive 70 / 100 points (basic questions):**\n",
    "1. Load \"text\" and \"target\" columns to pandas dataframe. Pick random 1000 lines from the dataframe. Compute average text length, and dictionary size.\n",
    "2. Find POSITIVE and NEGATIVE texts using flair or spacy. Add sentiment classification result to the dataframe. Supply this section with sentiment label distribution chart and discussion.\n",
    "3. Compare spacy (or flair) results with the \"target\" column, build confusion matrix and discuss it.\n",
    "4. Find all PERSONs and ORGANISATIONs in POSITIVE texts and add them to your dataframe. If there are multiple entities inside one text create separate lines for each entity.\n",
    "5. Find the most frequent PERSON and ORGANISATION in positive texts.\n",
    "5. Find the most frequent PERSON and ORGANISATION in positive texts.\n",
    "\n",
    "**To receive additional 30 / 100 points (advanced questions):**\n",
    "\n",
    "6. Cluster NEGATIVE texts using k-means clustering. Use tf-idf function to rank important phrases inside each document.\n",
    "7. Describe each NEGATIVE cluster with a list of key phrases or summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b71eb9",
   "metadata": {},
   "source": [
    "## Submission format\n",
    "You should submit your project as the python notebook (.ipynb) file and supplementary pdf file, generated from the python notebook. All questions of the Task section should be covered with code and markdown comments that are supposed to give a brief idea about what is happening in the code below and brief results discussion. Your report should be no longer than 5 pages including pictures.\n",
    "\n",
    "* Each section (1-7) should be supported with introduction and conclusion/discussion markdown text to be considered done.\n",
    "* The code cells should be executed and do not contain compilation and logical mistakes, there should not be unnecessary code and unused libraries inside the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d43851",
   "metadata": {},
   "source": [
    "## Tips and tricks\n",
    "\n",
    "You can use materials from practical sections of Module 5 “Contemporary Text Analysis”.\n",
    "In addition to that, below you can find the function to create a confusion matrix given the predicted and target columns in dataframe:\n",
    "``` python\n",
    "import pandas as pd\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str): return (df\n",
    ".groupby([col1, col2]) .size()\n",
    ".unstack(fill_value=0)\n",
    ") ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45928f0",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e3e8c",
   "metadata": {},
   "source": [
    "## Input block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffad34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librares\n",
    "#import kagglehub\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2b5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download latest version dataset\n",
    "#path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n",
    "\n",
    "#a = print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57121c",
   "metadata": {},
   "source": [
    "**Dataset description** from https://www.kaggle.com/datasets/kazanova/sentiment140/data\n",
    "\n",
    "**Context**\n",
    "\n",
    "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment.\n",
    "\n",
    "**Content**\n",
    "\n",
    "It contains the following 6 fields:\n",
    "\n",
    "1. target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "2. ids: The id of the tweet ( 2087)\n",
    "\n",
    "3. date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "4. flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "5. user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "6. text: the text of the tweet (Lyx is cool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8399b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import df\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', \n",
    "                 encoding='latin-1', \n",
    "                 names = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1eceb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a316ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
