{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea843de",
   "metadata": {},
   "source": [
    "# Homework information\n",
    "\n",
    "\n",
    "**Students:** Черкашина Елизавета Андреевна, Мешков Михаил Алексеевич\n",
    "\n",
    "**Master’s programme:** Data Analytics and Social Statistics\n",
    "\n",
    "**Task:**  Module 2. Hard skills project № 4 `Text analysis'\n",
    "\n",
    "**Date:** 17.12.2024  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7fa887",
   "metadata": {},
   "source": [
    "## Information about environment versions\n",
    "\n",
    "- Python 3.12.7\n",
    "- Pandas 2.2.3\n",
    "- Matplotlib 3.9.2\n",
    "- Spacy 3.8.3\n",
    "- Scikit-learn  1.5.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2583ebf",
   "metadata": {},
   "source": [
    "# Описание задачи (как сделаем можно убрать)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a53628",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "**To receive 70 / 100 points (basic questions):**\n",
    "1. Load \"text\" and \"target\" columns to pandas dataframe. Pick random 1000 lines from the dataframe. Compute average text length, and dictionary size.\n",
    "2. Find POSITIVE and NEGATIVE texts using flair or spacy. Add sentiment classification result to the dataframe. Supply this section with sentiment label distribution chart and discussion.\n",
    "3. Compare spacy (or flair) results with the \"target\" column, build confusion matrix and discuss it.\n",
    "4. Find all PERSONs and ORGANISATIONs in POSITIVE texts and add them to your dataframe. If there are multiple entities inside one text create separate lines for each entity.\n",
    "5. Find the most frequent PERSON and ORGANISATION in positive texts.\n",
    "5. Find the most frequent PERSON and ORGANISATION in positive texts.\n",
    "\n",
    "**To receive additional 30 / 100 points (advanced questions):**\n",
    "\n",
    "6. Cluster NEGATIVE texts using k-means clustering. Use tf-idf function to rank important phrases inside each document.\n",
    "7. Describe each NEGATIVE cluster with a list of key phrases or summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b71eb9",
   "metadata": {},
   "source": [
    "## Submission format\n",
    "You should submit your project as the python notebook (.ipynb) file and supplementary pdf file, generated from the python notebook. All questions of the Task section should be covered with code and markdown comments that are supposed to give a brief idea about what is happening in the code below and brief results discussion. Your report should be no longer than 5 pages including pictures.\n",
    "\n",
    "* Each section (1-7) should be supported with introduction and conclusion/discussion markdown text to be considered done.\n",
    "* The code cells should be executed and do not contain compilation and logical mistakes, there should not be unnecessary code and unused libraries inside the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d43851",
   "metadata": {},
   "source": [
    "## Tips and tricks\n",
    "\n",
    "You can use materials from practical sections of Module 5 “Contemporary Text Analysis”.\n",
    "In addition to that, below you can find the function to create a confusion matrix given the predicted and target columns in dataframe:\n",
    "``` python\n",
    "import pandas as pd\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str): return (df\n",
    ".groupby([col1, col2]) .size()\n",
    ".unstack(fill_value=0)\n",
    ") ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45928f0",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e3e8c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffad34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import kagglehub\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import spacy\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2b5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download latest version dataset via API, for download uncomment\n",
    "\n",
    "#path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baedc07d",
   "metadata": {},
   "source": [
    "## Task №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae71822",
   "metadata": {},
   "source": [
    "### 1.1 Load \"text\" and \"target\" columns to pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57121c",
   "metadata": {},
   "source": [
    "**Dataset description** from https://www.kaggle.com/datasets/kazanova/sentiment140/data\n",
    "\n",
    "**Context**\n",
    "\n",
    "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment.\n",
    "\n",
    "**Content**\n",
    "\n",
    "It contains the following 6 fields:\n",
    "\n",
    "1. target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "2. ids: The id of the tweet ( 2087)\n",
    "\n",
    "3. date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "4. flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "5. user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "6. text: the text of the tweet (Lyx is cool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8399b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('training.1600000.processed.noemoticon.csv', \n",
    "                 encoding='latin-1', \n",
    "                 names = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1eceb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking informathion about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a316ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5e530",
   "metadata": {},
   "source": [
    "**Conclusion:**  data loaded correctly and contain and information same as at the description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd95ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Going to pic quick  join?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>urg.  i should be somewhere I really want to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Help me!!!  Chanting NO CAKE NO CAKE!! LOL BD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@AritheGenius Awww,  we still love you though EB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trying to find my life again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>my house has become a bar. i want to go to bed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>Very Stormy here. I don't like. This huge burs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>i miss mcfly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>@_speranza hehe I managed to swipe a wee day o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>yay long weekend - work til 1 then done until ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0         4                          Going to pic quick  join?\n",
       "1         0  urg.  i should be somewhere I really want to b...\n",
       "2         4  Help me!!!  Chanting NO CAKE NO CAKE!! LOL BD ...\n",
       "3         0   @AritheGenius Awww,  we still love you though EB\n",
       "4         4                      trying to find my life again \n",
       "..      ...                                                ...\n",
       "995       0   my house has become a bar. i want to go to bed. \n",
       "996       0  Very Stormy here. I don't like. This huge burs...\n",
       "997       0                                   i miss mcfly... \n",
       "998       4  @_speranza hehe I managed to swipe a wee day o...\n",
       "999       4  yay long weekend - work til 1 then done until ...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the columns we'll be working with\n",
    "data_filtered = data[[\"target\", \"text\"]]\n",
    "# filter the random 1000 rows and making final df for work\n",
    "df = data_filtered.sample(n=1000, random_state=42425).reset_index(drop=True)\n",
    "# take a look at final df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8561eb",
   "metadata": {},
   "source": [
    "**Conclusion:**  data frame for work have been made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c7e70",
   "metadata": {},
   "source": [
    "### 1.2 Compute average text length, and dictionary size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceea53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734a8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making anonymous function to find tokens\n",
    "df['tokens'] = df['text'].apply(lambda x: [token.text.lower() \n",
    "                                           for token in nlp(x) \n",
    "                                           if token.is_alpha])\n",
    "\n",
    "# calculate average text length\n",
    "total_length = df['tokens'].apply(len).sum()\n",
    "average_length = total_length / len(df)\n",
    "\n",
    "# finding unique tokens\n",
    "unique_tokens = set(token for tokens in df['tokens'] for token in tokens)\n",
    "dictionary_size = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cca6efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConclusion:\u001b[0m\n",
      "Average text length: 11.97 tokens\n",
      "Dictionary size: 2914 tokens\n"
     ]
    }
   ],
   "source": [
    "print (\"\\033[1mConclusion:\\033[0m\")\n",
    "print(f\"Average text length: {average_length:.2f} tokens\")\n",
    "print(f\"Dictionary size: {dictionary_size} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8055582",
   "metadata": {},
   "source": [
    "## Task №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16035f92",
   "metadata": {},
   "source": [
    "## Task №3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204794f4",
   "metadata": {},
   "source": [
    "## Task №4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6661a",
   "metadata": {},
   "source": [
    "## Task №5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977c9b9",
   "metadata": {},
   "source": [
    "## Task №6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a78c66",
   "metadata": {},
   "source": [
    "## Task №7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
